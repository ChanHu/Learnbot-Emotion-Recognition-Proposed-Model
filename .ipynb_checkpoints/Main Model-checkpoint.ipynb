{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras.models import Sequential, Layer\n",
    "from keras.layers import Dense, MaxPool2D, Dropout,MaxPool2D, Activation,BatchNormalization, InputLayer, Embedding, Flatten, Conv2D,concatenate, MaxPooling2D, Input, TimeDistributed\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import keras.utils\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Flatten, LSTM\n",
    "import numpy as np\n",
    "from keras import objectives\n",
    "from __future__ import absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64, 3)\n",
      "(6, 10, 64, 64, 3)\n",
      "(6,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = np.random.rand(10,64,64,3).reshape(-1,64,64,3)\n",
    "s2 = np.random.rand(10,64,64,3).reshape(-1,64,64,3)\n",
    "s3 = np.random.rand(10,64,64,3).reshape(-1,64,64,3)\n",
    "s4 = np.random.rand(10,64,64,3).reshape(-1,64,64,3)\n",
    "s5 = np.random.rand(10,64,64,3).reshape(-1,64,64,3)\n",
    "s6 = np.random.rand(10,64,64,3).reshape(-1,64,64,3)\n",
    "data = np.array([s1,s2,s3,s4,s5,s6]).reshape(-1,10,64,64,3)\n",
    "label = np.array([0,1,2,3,4,5]).reshape(-1)\n",
    "print(s1.shape)\n",
    "print(data.shape)\n",
    "print(label.shape)\n",
    "label = keras.utils.to_categorical(label, num_classes=None)\n",
    "K.set_image_data_format('channels_last')\n",
    "K.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRegularization(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CustomRegularization, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self ,x ,mask=None):\n",
    "        x = cossimilasrity(x)#[Nf,1]\n",
    "        obejective.mean_squared_error(y_true, y_pred)\n",
    "        return bce\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        print(input_shape)\n",
    "        return ((None, 1, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cossimilasrity(x):\n",
    "    print(x)\n",
    "    return np.random.rand(10).astype('f').reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(y_true, y_pred):\n",
    "    print(\"loss_func\")\n",
    "    y_true = cossimilasrity(y_true)\n",
    "    y_pred = cossimilasrity(y_pred)\n",
    "    print(y_true.shape)\n",
    "    print(y_pred.shape)\n",
    "    loss = objectives.mean_squared_error(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_func\n",
      "(10, 1)\n",
      "(10, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_321 (TimeDi (None, 10, 60, 60, 64)    4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization_129 (Bat (None, 10, 60, 60, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_322 (TimeDi (None, 10, 60, 60, 64)    36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_130 (Bat (None, 10, 60, 60, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_323 (TimeDi (None, 10, 30, 30, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_324 (TimeDi (None, 10, 30, 30, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_325 (TimeDi (None, 10, 30, 30, 32)    18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_131 (Bat (None, 10, 30, 30, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_326 (TimeDi (None, 10, 30, 30, 32)    9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_132 (Bat (None, 10, 30, 30, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_327 (TimeDi (None, 10, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_328 (TimeDi (None, 10, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_329 (TimeDi (None, 10, 7200)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_330 (TimeDi (None, 10, 512)           3686912   \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 10, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "lstm_32 (LSTM)               (None, 6)                 12456     \n",
      "=================================================================\n",
      "Total params: 5,868,840\n",
      "Trainable params: 5,868,456\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv2D(64, 5, data_format=\"channels_last\", kernel_initializer=\"he_normal\", activation='relu'), input_shape=s1.shape))\n",
    "#model.add(TimeDistributed())\n",
    "model.add(BatchNormalization())\n",
    "model.add(TimeDistributed(Conv2D(64, (3,3),  padding='same', activation='relu')))\n",
    "# model.add(TimeDistributed())\n",
    "model.add(BatchNormalization())\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(Dropout(0.5)))\n",
    "model.add(TimeDistributed(Conv2D(32, (3,3),padding='same',activation='relu')))\n",
    "# model.add(TimeDistributed())\n",
    "model.add(BatchNormalization())\n",
    "model.add(TimeDistributed(Conv2D(32, (3,3),padding='same',activation='relu')))\n",
    "# model.add(TimeDistributed())\n",
    "model.add(BatchNormalization())\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(Dropout(0.5)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512)))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#freeze\n",
    "model.add(LSTM(512, return_sequences=True, dropout=0.2))\n",
    "#model.add(CustomRegularization())\n",
    "model.compile(loss= loss_func, optimizer = 'adam', metrics=['accuracy'])#E2 Objective Covered\n",
    "#freeze\n",
    "#model.add()\n",
    "model.add(LSTM(6, return_sequences=False, dropout=0.2))#E1 Objective Covered\n",
    "model.add(Activation('softmax'))\n",
    "#model.add(Dense(6, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])#'categorical_crossentropy'\n",
    "#compile E3 layerlstm\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 17s 3s/step - loss: 5.5280 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 6.7738 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 5.8141 - acc: 0.1667\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 2.6863 - acc: 0.1667   \n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 2.6863 - acc: 0.1667    \n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 10.7454 - acc: 0.1667\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 16.1181 - acc: 0.1667\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 13.4317 - acc: 0.1667\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 10.7454 - acc: 0.1667\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 10.7454 - acc: 0.1667\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 8.0590 - acc: 0.1667\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 8.0590 - acc: 0.1667  \n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.1921e-07 - acc: 0.1667\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 5.4339 - acc: 0.1667\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 13.4317 - acc: 0.1667 \n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.3333 \n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 5.3801 - acc: 0.3333\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 8.0951 - acc: 0.1667  \n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 10.8076 - acc: 0.1667\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 2.6863 - acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 8.0590 - acc: 0.3333\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 13.4317 - acc: 0.1667 \n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 8.0590 - acc: 0.1667 \n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 5.3727 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 10.7454 - acc: 0.3333\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 2.6863 - acc: 0.1667  \n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 8.0590 - acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 5.3727 - acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 8.0590 - acc: 0.3333\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 5.3727 - acc: 0.1667\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 8.0590 - acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 8.0590 - acc: 0.1667\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 10.7454 - acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 9s 1s/step - loss: 8.0590 - acc: 0.1667\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 8.0590 - acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 10.7454 - acc: 0.1667\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 2.6863 - acc: 0.1667\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.1667\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.1667   \n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 9s 1s/step - loss: 8.0590 - acc: 0.1667 \n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 10.7454 - acc: 0.1667\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 5.3727 - acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 10.7454 - acc: 0.1667\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.1667  \n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.3333\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 10.7454 - acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.1667\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 8.0590 - acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.3333\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 5.3727 - acc: 0.1667\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 5.3727 - acc: 0.1667\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 10.7454 - acc: 0.1667\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 10.7454 - acc: 0.1667\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 5.3727 - acc: 0.3333 \n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 5.3727 - acc: 0.3333\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 10.7454 - acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 10.7454 - acc: 0.1667\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 8.0590 - acc: 0.3333\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 10.7454 - acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 10.7454 - acc: 0.1667\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.3333\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 2.6863 - acc: 0.3333\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 9s 1s/step - loss: 8.0590 - acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 9s 1s/step - loss: 10.7454 - acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 8.0590 - acc: 0.1667\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 5.3727 - acc: 0.3333\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.3333\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 9s 1s/step - loss: 8.0590 - acc: 0.1667\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 9s 1s/step - loss: 8.0590 - acc: 0.1667\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 9s 1s/step - loss: 8.0590 - acc: 0.1667 \n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.1667\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 2.6863 - acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 9s 1s/step - loss: 8.0590 - acc: 0.1667 \n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 8.0590 - acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 13.4317 - acc: 0.3333\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 5.3727 - acc: 0.1667 \n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 9s 1s/step - loss: 8.0590 - acc: 0.3333 \n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 8.0590 - acc: 0.1667\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 5.3727 - acc: 0.1667  \n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 8.0590 - acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.1667 \n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.1667\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 7s 1s/step - loss: 5.3727 - acc: 0.1667\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 13.4317 - acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.1667 \n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 5.3727 - acc: 0.1667 \n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 8.0590 - acc: 0.3333\n",
      "Epoch 94/100\n",
      "4/6 [===================>..........] - ETA: 2s - loss: 8.0590 - acc: 0.0000e+00 "
     ]
    }
   ],
   "source": [
    "model.fit(data, label, batch_size=1, epochs = 100)\n",
    "# score, acc = model.evaluate(data, label)\n",
    "# print('Test score:', score)\n",
    "# print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 60, 60, 64)        4864      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 57, 57, 64)        65600     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 57, 57, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 26, 26, 32)        18464     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               2359808   \n",
      "=================================================================\n",
      "Total params: 2,458,112\n",
      "Trainable params: 2,458,048\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#cnn mian\n",
    "cnnmodel = Sequential()\n",
    "cnnmodel.add(Conv2D(64, 5, data_format=\"channels_last\", kernel_initializer=\"he_normal\", \n",
    "                 input_shape=(64, 64, 3)))\n",
    "#cnnmodel.add(BatchNormalization())\n",
    "cnnmodel.add(Activation(\"relu\"))\n",
    "\n",
    "cnnmodel.add(Conv2D(64, 4))\n",
    "#cnnmodel.add(BatchNormalization())\n",
    "cnnmodel.add(Activation(\"relu\"))\n",
    "cnnmodel.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "cnnmodel.add(Dropout(0.5))\n",
    "\n",
    "cnnmodel.add(Conv2D(32, 3))\n",
    "#cnnmodel.add(BatchNormalization())\n",
    "cnnmodel.add(Activation(\"relu\"))\n",
    "\n",
    "cnnmodel.add(Conv2D(32, 3))\n",
    "cnnmodel.add(keras.layers.normalization.BatchNormalization())#BatchNormalization())\n",
    "cnnmodel.add(Activation(\"relu\"))\n",
    "\n",
    "cnnmodel.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "cnnmodel.add(Dropout(0.5))\n",
    "\n",
    "cnnmodel.add(Flatten())\n",
    "cnnmodel.add(Dense(512))\n",
    "cnnmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnnmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_8 (TimeDist (None, 1000, 60, 60, 64)  4864      \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 1000, 58, 58, 32)  18464     \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 1000, 29, 29, 32)  0         \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 1000, 29, 29, 64)  18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 1000, 29, 29, 64)  36928     \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 1000, 14, 14, 64)  0         \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 1000, 14, 14, 128) 73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 1000, 14, 14, 128) 147584    \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 1000, 7, 7, 128)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 1000, 7, 7, 256)   295168    \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 1000, 7, 7, 256)   590080    \n",
      "_________________________________________________________________\n",
      "time_distributed_19 (TimeDis (None, 1000, 3, 3, 256)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_20 (TimeDis (None, 1000, 3, 3, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "time_distributed_21 (TimeDis (None, 1000, 3, 3, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "time_distributed_22 (TimeDis (None, 1000, 1, 1, 512)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1000, 1, 1, 512)   2048      \n",
      "_________________________________________________________________\n",
      "time_distributed_23 (TimeDis (None, 1000, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000, 512)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1000, 256)         787456    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000, 6)           1542      \n",
      "=================================================================\n",
      "Total params: 5,516,454\n",
      "Trainable params: 5,515,430\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## approach 2\n",
    "model = Sequential()\n",
    "sequence = Input(shape=[None, 64, 64, 3])\n",
    "model.add(TimeDistributed(Conv2D(64, 5, data_format=\"channels_last\", kernel_initializer=\"he_normal\"), input_shape=(1000, 64, 64, 3)))\n",
    "model.add(TimeDistributed(Conv2D(32, (3,3),  padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(128, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(128, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(256, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(256, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(512, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(512, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(BatchNormalization())\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(256, return_sequences=True, dropout=0.5))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
